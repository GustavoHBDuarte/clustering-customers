{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd4a8c4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a791ea2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color=\"green\">Library imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4717f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:02:31.096304Z",
     "start_time": "2022-03-07T04:02:31.092586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import inflection\n",
    "import re\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import pickle\n",
    "import boto3\n",
    "import boto3.session\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459fe64",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color=\"blue\">Loading data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de8e6756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:02:33.494956Z",
     "start_time": "2022-03-07T04:02:32.653061Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "db_credentials = pd.read_csv('s3://gustavoawsbucketds/db_credentials.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a5ce827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:02:34.360956Z",
     "start_time": "2022-03-07T04:02:34.358098Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# DB creentials\n",
    "\n",
    "user = db_credentials[0][0]\n",
    "psw = db_credentials[1][0]\n",
    "host = db_credentials[2][0]\n",
    "port = db_credentials[3][0]\n",
    "schema = db_credentials[4][0]\n",
    "schema_2 = db_credentials[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c03867f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:03:09.614678Z",
     "start_time": "2022-03-07T04:02:35.235626Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Selecting data from database - SQL query ('purchases' table - ecommerce schema)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM purchases\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}'.format(user, psw, host, port, schema))\n",
    "\n",
    "# executing sql query\n",
    "df = pd.read_sql_query(query, con=connection)\n",
    "\n",
    "# closing database connection\n",
    "connection.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee931b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1 - Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbeb5711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:01.026891Z",
     "start_time": "2022-03-07T04:05:00.960264Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe9966",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font color=\"gray\">1.1 Rename columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "928f84b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:02.516846Z",
     "start_time": "2022-03-07T04:05:02.510138Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adjusting column names\n",
    "\n",
    "df_1.columns = list(map(lambda x: inflection.underscore(x), df.columns)) #changing to underscore + lower(snakecase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1614b25",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font color=\"gray\">1.5 Replace NA's</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12642427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:03.744769Z",
     "start_time": "2022-03-07T04:05:03.630612Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_1 = df_1.dropna(subset=['description', 'customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454a8de",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font color=\"gray\">1.6 Changing data types</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e95a47f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:05.233871Z",
     "start_time": "2022-03-07T04:05:05.089319Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Changing column 'invoice_date' to datetime\n",
    "\n",
    "df_1['invoice_date'] = pd.to_datetime(df_1['invoice_date'], format='%d-%b-%y')\n",
    "\n",
    "\n",
    "# Changing column 'customer_id' to int\n",
    "\n",
    "df_1['customer_id'] = df_1['customer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b6ab88",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2 - Data filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8ad1c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we detected some data inconsistency in the previous subtopic, we are going to process these inconsistensy here to clean the data so we can get cleaned data for feature engineering.\n",
    "\n",
    "Inconsistencies previously raised:\n",
    "\n",
    "1- Negative quantity (can be return)\n",
    "\n",
    "2- unity price with min == 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "229a2a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:07.644924Z",
     "start_time": "2022-03-07T04:05:07.607517Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eec996bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:09.095525Z",
     "start_time": "2022-03-07T04:05:08.864476Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Removing inconsistencies\n",
    "\n",
    "\n",
    "# 'unit_price' column:\n",
    "\n",
    "# we are going to ignore 'unit_price'==0. We will consider 'unite_price'>0.04\n",
    "\n",
    "df_2 = df_2.loc[df_2['unit_price']>0.04, :]\n",
    "\n",
    "\n",
    "\n",
    "# 'stock_code' column:\n",
    "\n",
    "# removing the rows where the values are one of these: ['POST' 'D' 'M' 'PADS' 'DOT' 'CRUK']\n",
    "df_2 = df_2.loc[~df_2['stock_code'].isin(['POST' 'D' 'M' 'PADS' 'DOT' 'CRUK'])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'description' column:\n",
    "\n",
    "# removing 'description' column assuming it does not have relevance information\n",
    "df_2 = df_2.drop(columns='description')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'country' column (map)\n",
    "\n",
    "# removing rows where 'country' == 'European Community', 'Unspecified'\n",
    "df_2 = df_2.loc[~df_2['country'].isin(['European Community', 'Unspecified']), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'quantity' column:\n",
    "\n",
    "# getting a dataframe with only returns operations\n",
    "df_2_returns = df_2.loc[df_2['quantity'] < 0, :]\n",
    "\n",
    "# getting a dataframe with only purchases operations\n",
    "df_2_purchases = df_2.loc[df_2['quantity'] >= 0, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f3363cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:10.160434Z",
     "start_time": "2022-03-07T04:05:10.115089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Removing inconsistencies in observations:\n",
    "\n",
    "\n",
    "# based on previous univariate analysis, we investigated for some potential outliers (customers with unusual purchase behaviour)\n",
    "\n",
    "## we are going to remove these observations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'customer_id' == 16446 (this customer had two records that do not represent actual purchases, and 2 more records with only 1 item purchased each)\n",
    "## should be removed because this customer is generating distortion in the avg_ticket calculation\n",
    "\n",
    "df_2_purchases = df_2_purchases[~df_2_purchases['customer_id'].isin([16446])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5725e366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:32.862880Z",
     "start_time": "2022-03-07T04:05:11.876187Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "\n",
    "# Saving cleaned purchases table into a sql database to be further consumed by an external visualization tool via sql query\n",
    "\n",
    "\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(user, psw, host, port, schema_2))\n",
    "\n",
    "# inserting data to database\n",
    "df_2_purchases.to_sql( 'purchases', con=connection, if_exists='append', index=False)\n",
    "\n",
    "# ====================================================================\n",
    "\n",
    "# closing database connection\n",
    "connection.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e2023",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3 - Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba0a5ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:36.826296Z",
     "start_time": "2022-03-07T04:05:36.783602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111b873",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font color=\"gray\">3.1 Feature creation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e068b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "New features will be created in a new dataframe which each row is going to be a different customer. In this next snippet we will create a separated dataframe with only customer_id information.\n",
    "\n",
    "This new dataframe (df_ref) will be the main dataframe to apply machine learning to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3132da70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:39.118951Z",
     "start_time": "2022-03-07T04:05:39.103158Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating reference dataframe\n",
    "\n",
    "df_ref = df_3.drop(['invoice_no', 'stock_code', 'quantity', 'invoice_date',\n",
    "                   'unit_price', 'country'], axis=1).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f2bb8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this new df name df_ref we are going to add new columns ('gross_revenue', 'recency' and 'frequency') that will be filled using information provided by main dataframe (df_3). This dataframe will provide us information of each costumer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e27a0d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:42.418263Z",
     "start_time": "2022-03-07T04:05:41.114793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating 'gross_revenue' column to df_2_purchases (gross_revenue = unit_price * quantity)\n",
    "\n",
    "df_2_purchases['gross_revenue'] = df_2_purchases['unit_price'] * df_2_purchases['quantity']\n",
    "\n",
    "\n",
    "\n",
    "# Monetary (grouping 'gross_revenue' by customer)\n",
    "\n",
    "df_monetary = df_2_purchases[['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "\n",
    "\n",
    "# Joining df_ref and df_monetary\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_monetary, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recency - last day purchase (grouping 'invoice_date' by customer and getting de max date)\n",
    "\n",
    "df_recency = df_2_purchases[['customer_id', 'invoice_date']].groupby('customer_id').max().reset_index() # creating df_recency\n",
    "\n",
    "df_recency['recency'] = df_2_purchases['invoice_date'].max() - df_recency['invoice_date'] # adding 'recency' column (last purchase day of each customer - max day of dataset)\n",
    "\n",
    "df_recency['recency'] = df_recency['recency'].apply( lambda x: x.days) # extrating the number of days (from X days)\n",
    "\n",
    "\n",
    "# Joining df_ref and df_recency\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_recency[['customer_id','recency']], how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Quantity of purchases by costumer - purchase frequency of each customer\n",
    "\n",
    "df_purch_cost = df_2_purchases[['customer_id','invoice_no']].drop_duplicates().groupby('customer_id').count().reset_index()\n",
    "df_purch_cost.columns = ['customer_id', 'purchase_by_costumer'] # renaming column 'invoice' to 'purchase_by_costumer'\n",
    "\n",
    "\n",
    "# Joining df_ref and df_purch_cost\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_purch_cost, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Number of items purchased\n",
    "\n",
    "df_total_purchased = df_2_purchases[['customer_id','quantity']].groupby('customer_id').sum().reset_index()\n",
    "df_total_purchased.columns = ['customer_id', 'number_items_purchased'] # renaming column 'invoice' to 'purchase_by_costumer'\n",
    "\n",
    "\n",
    "# Joining df_ref and df_total_purchased\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_total_purchased, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Number of products purchased\n",
    "\n",
    "df_total_products = df_2_purchases[['customer_id','stock_code']].groupby('customer_id').count().reset_index()\n",
    "df_total_products.columns = ['customer_id', 'number_products_purchased'] # renaming column 'invoice' to 'purchase_by_costumer'\n",
    "\n",
    "\n",
    "# Joining df_ref and df_total_purchased\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_total_products, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Average ticket - mean purchase amount\n",
    "\n",
    "df_avg_ticket = df_2_purchases[['customer_id','gross_revenue']].groupby('customer_id').mean().reset_index()\n",
    "df_avg_ticket.columns = ['customer_id', 'avg_ticket']\n",
    "\n",
    "\n",
    "# Joining df_ref and df_avg_ticket\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_avg_ticket, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Average period between purchases\n",
    "\n",
    "\n",
    "df_aux = df_2_purchases[['customer_id', 'invoice_date']].drop_duplicates().sort_values(['customer_id','invoice_date'],\n",
    "                                                                             ascending=['False', 'False'])\n",
    "\n",
    "df_aux['previous_costumer_id'] = df_aux['customer_id'].shift() #getting next row's custumer_id\n",
    "\n",
    "df_aux['previous_invoice_date'] = df_aux['invoice_date'].shift() #getting next row's invoice_date\n",
    "\n",
    "\n",
    "df_aux['recency_days'] = df_aux.apply(lambda x: (x['invoice_date'] - x['previous_invoice_date']).days +1 \n",
    "                                                    if x['customer_id'] == x['previous_costumer_id'] else np.nan, axis=1)\n",
    "\n",
    "df_aux = df_aux.drop(columns=['invoice_date', 'previous_costumer_id', 'previous_invoice_date']) # droping auxiliary columns \n",
    "\n",
    "df_aux = df_aux.dropna() # droping Na's\n",
    "\n",
    "df_avg_recency_days = df_aux.groupby('customer_id').mean().reset_index()\n",
    "\n",
    "df_avg_recency_days.columns = ['customer_id', 'mean_recency_days']\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_avg_recency_days\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_avg_recency_days, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Frequency purchase (mean of unique purchases/time interval between the first and the last purchase)\n",
    "\n",
    "\n",
    "df_aux = (df_2_purchases[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                                       .groupby('customer_id')\n",
    "                                                                       .agg(max_ = ('invoice_date', 'max'),\n",
    "                                                                            min_ = ('invoice_date', 'min'),\n",
    "                                                                            days_ = ('invoice_date', lambda x: (((x.max()-x.min()).days)+1)),\n",
    "                                                                            buy_ = ('invoice_no', 'count'))).reset_index()\n",
    "\n",
    "df_aux['frequency'] = df_aux[['days_', 'buy_']].apply(lambda x: x['buy_']/x['days_'] if x['days_'] != 0 else 0 , axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_aux\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_aux[['frequency', 'customer_id']], how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Returns - number of returns\n",
    "\n",
    "df_ret = (df_2_returns[['customer_id', 'quantity']].groupby('customer_id')\n",
    "                                                   .sum()\n",
    "                                                   .reset_index()\n",
    "                                                   .drop_duplicates()\n",
    "                                                   .rename(columns={'quantity':'number_of_returns'}))\n",
    " \n",
    "df_ret['number_of_returns'] = df_ret['number_of_returns']*-1 # getting positive values\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_ret\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_ret, how='left', on='customer_id')\n",
    "df_ref['number_of_returns'].fillna(0, inplace=True) # filling 'number_of_returns' with zero (when customer have never returned a product purchased)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Basket size - mean quantity (sum) of products in each purchase by costumer\n",
    "\n",
    "\n",
    "\n",
    "df_aux = (df_2_purchases[['customer_id', 'invoice_no', 'quantity']].groupby('customer_id')\n",
    "                                                                   .agg(n_purchases=('invoice_no', 'nunique'),\n",
    "                                                                        n_products=('quantity', 'sum'))\n",
    "                                                                   .reset_index())\n",
    "\n",
    "df_aux['avg_basket_size'] = df_aux['n_products']/df_aux['n_purchases'] # calculating avg basket size of each customer\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_aux\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_aux[['customer_id','avg_basket_size']], how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Basket size unique - mean quantity (sum) of unique products in each purchase by costumer\n",
    "\n",
    "\n",
    "\n",
    "df_aux = (df_2_purchases[['customer_id', 'invoice_no', 'stock_code']].groupby('customer_id')\n",
    "                                                                     .agg(n_purchases=('invoice_no', 'nunique'),\n",
    "                                                                          n_products=('stock_code', 'count'))\n",
    "                                                                     .reset_index())\n",
    "\n",
    "df_aux['avg_unique_basket_size'] = df_aux['n_products']/df_aux['n_purchases'] # calculating avg basket size of each customer\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_aux\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_aux[['customer_id','avg_unique_basket_size']], how='left', on='customer_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09656407",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5 - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5fdd8231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:05:47.128744Z",
     "start_time": "2022-03-07T04:05:47.123347Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#droping NA's generated from the previous step:\n",
    "df_4 = df_ref.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c245b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font color=\"gray\"><i>4.3.4 Tree-based embedding</i></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f625e0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our strategy here is to fit a Random Forest Regressor using the column 'gross_revenue' as target variable/objective function assuming the this feature is important for clustering valuable customers. After fitting the model we expect to get more organized data to use as input to check clustering behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fe58916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:06:08.124549Z",
     "start_time": "2022-03-07T04:05:55.915978Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# defining 'gross_revenue' as target variable\n",
    "\n",
    "y = df_4['gross_revenue']\n",
    "\n",
    "X = df_4.drop(columns='gross_revenue')\n",
    "X = X.set_index('customer_id')\n",
    "\n",
    "\n",
    "# Loading tree model from AWS S3\n",
    "\n",
    "# getting bucket name\n",
    "for bucket_name in boto3.resource('s3').buckets.all():\n",
    "    bucket_name = bucket_name.name\n",
    "\n",
    "\n",
    "# getting credentials\n",
    "cred = boto3.Session().get_credentials()\n",
    "ACCESS_KEY = cred.access_key\n",
    "SECRET_KEY = cred.secret_key\n",
    "\n",
    "s3client = boto3.client('s3', \n",
    "                        aws_access_key_id = ACCESS_KEY, \n",
    "                        aws_secret_access_key = SECRET_KEY\n",
    "                       )\n",
    "#responde\n",
    "response = s3client.get_object(Bucket=bucket_name, Key='rf_model.pkl')\n",
    "\n",
    "body = response['Body'].read()\n",
    "\n",
    "#tree\n",
    "rf = pickle.loads(body)\n",
    "\n",
    "\n",
    "# getting leaf information\n",
    "leaf = rf.apply(X)\n",
    "\n",
    "# df leaf\n",
    "df_leaf = pd.DataFrame(leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e0e18",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Random Forest just created an organized embedded data space. We are going to apply dimension reduction techniques (since we got here 100 of variables making necessary dimension reduction) to see if there is some clustering behaviour among samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d743cd9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### <font color=\"gray\"><i>4.3.4.1 Applying UMAP to tree-embedded data</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6edfb1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:06:15.504917Z",
     "start_time": "2022-03-07T04:06:12.944985Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loading fitted reducer from AWS S3\n",
    "\n",
    "# getting bucket name\n",
    "for bucket_name in boto3.resource('s3').buckets.all():\n",
    "    bucket_name = bucket_name.name\n",
    "\n",
    "\n",
    "# getting credentials\n",
    "cred = boto3.Session().get_credentials()\n",
    "ACCESS_KEY = cred.access_key\n",
    "SECRET_KEY = cred.secret_key\n",
    "\n",
    "s3client = boto3.client('s3', \n",
    "                        aws_access_key_id = ACCESS_KEY, \n",
    "                        aws_secret_access_key = SECRET_KEY\n",
    "                       )\n",
    "#responde\n",
    "response = s3client.get_object(Bucket=bucket_name, Key='reducer_umap.pkl')\n",
    "\n",
    "body = response['Body'].read()\n",
    "\n",
    "#embedding\n",
    "reducer_umap = pickle.loads(body)\n",
    "\n",
    "embedding = reducer_umap.transform(df_leaf)\n",
    "\n",
    "# getting axis for plot and clustering\n",
    "df_tree_umap = pd.DataFrame()\n",
    "df_tree_umap['embeddings_x'] = embedding[:,0]\n",
    "df_tree_umap['embeddings_y'] = embedding[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d250c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 8 - Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e7751",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font color=\"gray\">8.1 K-Means </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca33342",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font color=\"gray\">8.1 K-Means with tree-based embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aacef1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For embedded model we are going to fit the model using k=11 (decision made based on analysis above - WSS and SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "104f0a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:06:20.698538Z",
     "start_time": "2022-03-07T04:06:20.591895Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "k = 11\n",
    "\n",
    "\n",
    "# instantiating the model\n",
    "\n",
    "model_embedded = KMeans(init='random', n_clusters=k, n_init=10, max_iter=300, random_state=42)\n",
    "\n",
    "\n",
    "# fitting the model\n",
    "\n",
    "model_embedded.fit(df_tree_umap)\n",
    "\n",
    "\n",
    "# predicting labels/clusters\n",
    "\n",
    "labels_embedded = model_embedded.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc4ab4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font color=\"gray\">8.2 Cluster validation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4cde0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:06:29.653942Z",
     "start_time": "2022-03-07T04:06:29.493327Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans metrics:\n",
      "\n",
      "WSS: 14574.41\n",
      "Silhouette score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Embedded model - metrics\n",
    "print('Kmeans metrics:\\n')\n",
    "\n",
    "# WSS\n",
    "print('WSS: {:.2f}'.format(model_embedded.inertia_))\n",
    "\n",
    "# SS\n",
    "print('Silhouette score: {:.2f}'.format(round(silhouette_score(df_tree_umap, labels_embedded, metric='euclidean', random_state=42),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd6b1d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 9 - Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c26d9f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:06:37.709318Z",
     "start_time": "2022-03-07T04:06:37.702585Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adding embedded 'cluster/label' column to df_4_2 (df_4 without data transforming. For cluster profile report)\n",
    "\n",
    "df_4_2 = df_4.copy()\n",
    "df_4_2['label'] = labels_embedded+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1bff3bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:06:39.650029Z",
     "start_time": "2022-03-07T04:06:39.637032Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Renaming the best cluster to \"Golden\"\n",
    "\n",
    "# getting cluster number of the Golden group\n",
    "cluster_number = df_4_2[['gross_revenue', 'label']].groupby('label').mean().reset_index().sort_values(by='gross_revenue', ascending=False).iloc[0,0]\n",
    "\n",
    "# replacing the cluster number to 'Golden'\n",
    "df_4_2.loc[df_4_2['label']==cluster_number, 'label'] = 'Golden'\n",
    "\n",
    "# droping mean-related columns\n",
    "df_4_2 = df_4_2.drop(columns=['avg_ticket', 'mean_recency_days', 'avg_basket_size', 'avg_unique_basket_size'])\n",
    "\n",
    "\n",
    "# changing data types\n",
    "df_4_2['recency'] = df_4_2['recency'].astype('int')\n",
    "\n",
    "df_4_2['purchase_by_costumer'] = df_4_2['purchase_by_costumer'].astype('int')\n",
    "\n",
    "df_4_2['number_items_purchased'] = df_4_2['number_items_purchased'].astype('int')\n",
    "\n",
    "df_4_2['number_products_purchased'] = df_4_2['number_products_purchased'].astype('int')\n",
    "\n",
    "df_4_2['number_of_returns'] = df_4_2['number_of_returns'].astype('int')\n",
    "\n",
    "\n",
    "# adding 'last_training_timestamp' column\n",
    "df_4_2['last_training_timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_4_2['last_training_timestamp'] = pd.to_datetime(df_4_2['last_training_timestamp'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03f12b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:06:44.400128Z",
     "start_time": "2022-03-07T04:06:41.168676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "\n",
    "# Inserting data to sql database using SQLAlchemy (SQLAlchemy is able to insert data into several databases)\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(user, psw, host, port, schema_2))\n",
    "\n",
    "# inserting data to database\n",
    "df_4_2.to_sql( 'customers', con=connection, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "\n",
    "# closing database connection\n",
    "connection.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c56c20",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 11 - Database queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08d66701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:07:03.230913Z",
     "start_time": "2022-03-07T04:07:00.812860Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>recency</th>\n",
       "      <th>purchase_by_costumer</th>\n",
       "      <th>number_items_purchased</th>\n",
       "      <th>number_products_purchased</th>\n",
       "      <th>frequency</th>\n",
       "      <th>number_of_returns</th>\n",
       "      <th>label</th>\n",
       "      <th>last_training_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850</td>\n",
       "      <td>5391.21</td>\n",
       "      <td>372</td>\n",
       "      <td>34</td>\n",
       "      <td>1733</td>\n",
       "      <td>297</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13047</td>\n",
       "      <td>3237.54</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1391</td>\n",
       "      <td>172</td>\n",
       "      <td>0.029155</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12583</td>\n",
       "      <td>7281.38</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5060</td>\n",
       "      <td>247</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>51</td>\n",
       "      <td>Golden</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13748</td>\n",
       "      <td>948.25</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>439</td>\n",
       "      <td>28</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15100</td>\n",
       "      <td>876.00</td>\n",
       "      <td>333</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>13596</td>\n",
       "      <td>697.04</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>406</td>\n",
       "      <td>166</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>14893</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>799</td>\n",
       "      <td>73</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>14126</td>\n",
       "      <td>706.13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>508</td>\n",
       "      <td>15</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>13521</td>\n",
       "      <td>1093.65</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>736</td>\n",
       "      <td>436</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>15060</td>\n",
       "      <td>303.09</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>263</td>\n",
       "      <td>121</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-03-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2785 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  gross_revenue  recency  purchase_by_costumer  \\\n",
       "0           17850        5391.21      372                    34   \n",
       "1           13047        3237.54       31                    10   \n",
       "2           12583        7281.38        2                    15   \n",
       "3           13748         948.25       95                     5   \n",
       "4           15100         876.00      333                     3   \n",
       "...           ...            ...      ...                   ...   \n",
       "2780        13596         697.04        5                     2   \n",
       "2781        14893        1237.85        9                     2   \n",
       "2782        14126         706.13        7                     3   \n",
       "2783        13521        1093.65        1                     3   \n",
       "2784        15060         303.09        8                     4   \n",
       "\n",
       "      number_items_purchased  number_products_purchased  frequency  \\\n",
       "0                       1733                        297  17.000000   \n",
       "1                       1391                        172   0.029155   \n",
       "2                       5060                        247   0.040323   \n",
       "3                        439                         28   0.017921   \n",
       "4                         80                          3   0.073171   \n",
       "...                      ...                        ...        ...   \n",
       "2780                     406                        166   0.250000   \n",
       "2781                     799                         73   0.666667   \n",
       "2782                     508                         15   0.750000   \n",
       "2783                     736                        436   0.300000   \n",
       "2784                     263                        121   2.000000   \n",
       "\n",
       "      number_of_returns   label last_training_timestamp  \n",
       "0                    40      10              2022-03-07  \n",
       "1                    36      10              2022-03-07  \n",
       "2                    51  Golden              2022-03-07  \n",
       "3                     0       1              2022-03-07  \n",
       "4                    22       2              2022-03-07  \n",
       "...                 ...     ...                     ...  \n",
       "2780                  0       1              2022-03-07  \n",
       "2781                  0      11              2022-03-07  \n",
       "2782                 50       5              2022-03-07  \n",
       "2783                  0      11              2022-03-07  \n",
       "2784                  0       7              2022-03-07  \n",
       "\n",
       "[2785 rows x 10 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting data from database - SQL query ('customers' table)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM customers\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(user, psw, host, port, schema_2))\n",
    "\n",
    "# executing sql query\n",
    "pd.read_sql_query(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96ba313d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:07:17.699122Z",
     "start_time": "2022-03-07T04:07:08.128192Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_no</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>quantity</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397502</th>\n",
       "      <td>581587</td>\n",
       "      <td>22613</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397503</th>\n",
       "      <td>581587</td>\n",
       "      <td>22899</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>2.10</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397504</th>\n",
       "      <td>581587</td>\n",
       "      <td>23254</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397505</th>\n",
       "      <td>581587</td>\n",
       "      <td>23255</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397506</th>\n",
       "      <td>581587</td>\n",
       "      <td>22138</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>4.95</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397507 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       invoice_no stock_code  quantity invoice_date  unit_price  customer_id  \\\n",
       "0          536365     85123A         6   2016-11-29        2.55        17850   \n",
       "1          536365      71053         6   2016-11-29        3.39        17850   \n",
       "2          536365     84406B         8   2016-11-29        2.75        17850   \n",
       "3          536365     84029G         6   2016-11-29        3.39        17850   \n",
       "4          536365     84029E         6   2016-11-29        3.39        17850   \n",
       "...           ...        ...       ...          ...         ...          ...   \n",
       "397502     581587      22613        12   2017-12-07        0.85        12680   \n",
       "397503     581587      22899         6   2017-12-07        2.10        12680   \n",
       "397504     581587      23254         4   2017-12-07        4.15        12680   \n",
       "397505     581587      23255         4   2017-12-07        4.15        12680   \n",
       "397506     581587      22138         3   2017-12-07        4.95        12680   \n",
       "\n",
       "               country  \n",
       "0       United Kingdom  \n",
       "1       United Kingdom  \n",
       "2       United Kingdom  \n",
       "3       United Kingdom  \n",
       "4       United Kingdom  \n",
       "...                ...  \n",
       "397502          France  \n",
       "397503          France  \n",
       "397504          France  \n",
       "397505          France  \n",
       "397506          France  \n",
       "\n",
       "[397507 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting data from database - SQL query ('purchases' table)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM purchases\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(user, psw, host, port, schema_2))\n",
    "\n",
    "# executing sql query\n",
    "pd.read_sql_query(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd27059d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:07:39.966858Z",
     "start_time": "2022-03-07T04:07:22.239614Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>29-Nov-16</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>29-Nov-16</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>29-Nov-16</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>29-Nov-16</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>29-Nov-16</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541904</th>\n",
       "      <td>581587</td>\n",
       "      <td>22613</td>\n",
       "      <td>PACK OF 20 SPACEBOY NAPKINS</td>\n",
       "      <td>12</td>\n",
       "      <td>7-Dec-17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541905</th>\n",
       "      <td>581587</td>\n",
       "      <td>22899</td>\n",
       "      <td>CHILDREN'S APRON DOLLY GIRL</td>\n",
       "      <td>6</td>\n",
       "      <td>7-Dec-17</td>\n",
       "      <td>2.10</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541906</th>\n",
       "      <td>581587</td>\n",
       "      <td>23254</td>\n",
       "      <td>CHILDRENS CUTLERY DOLLY GIRL</td>\n",
       "      <td>4</td>\n",
       "      <td>7-Dec-17</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541907</th>\n",
       "      <td>581587</td>\n",
       "      <td>23255</td>\n",
       "      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>\n",
       "      <td>4</td>\n",
       "      <td>7-Dec-17</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541908</th>\n",
       "      <td>581587</td>\n",
       "      <td>22138</td>\n",
       "      <td>BAKING SET 9 PIECE RETROSPOT</td>\n",
       "      <td>3</td>\n",
       "      <td>7-Dec-17</td>\n",
       "      <td>4.95</td>\n",
       "      <td>12680.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>541909 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0         536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1         536365     71053                  WHITE METAL LANTERN         6   \n",
       "2         536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3         536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4         536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "...          ...       ...                                  ...       ...   \n",
       "541904    581587     22613          PACK OF 20 SPACEBOY NAPKINS        12   \n",
       "541905    581587     22899         CHILDREN'S APRON DOLLY GIRL          6   \n",
       "541906    581587     23254        CHILDRENS CUTLERY DOLLY GIRL          4   \n",
       "541907    581587     23255      CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
       "541908    581587     22138        BAKING SET 9 PIECE RETROSPOT          3   \n",
       "\n",
       "       InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0        29-Nov-16       2.55     17850.0  United Kingdom  \n",
       "1        29-Nov-16       3.39     17850.0  United Kingdom  \n",
       "2        29-Nov-16       2.75     17850.0  United Kingdom  \n",
       "3        29-Nov-16       3.39     17850.0  United Kingdom  \n",
       "4        29-Nov-16       3.39     17850.0  United Kingdom  \n",
       "...            ...        ...         ...             ...  \n",
       "541904    7-Dec-17       0.85     12680.0          France  \n",
       "541905    7-Dec-17       2.10     12680.0          France  \n",
       "541906    7-Dec-17       4.15     12680.0          France  \n",
       "541907    7-Dec-17       4.15     12680.0          France  \n",
       "541908    7-Dec-17       4.95     12680.0          France  \n",
       "\n",
       "[541909 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting data from database - SQL query ('purchases' table - ecommerce schema)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM purchases\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(user, psw, host, port, schema))\n",
    "\n",
    "# executing sql query\n",
    "pd.read_sql_query(query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49b8c599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T04:08:04.669770Z",
     "start_time": "2022-03-07T04:08:04.667018Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# closing database connection\n",
    "connection.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90464e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61c715b3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 12 - Production code (.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958bd3fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T01:49:07.173204Z",
     "start_time": "2022-03-08T01:47:40.530462Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans metrics:\n",
      "\n",
      "WSS: 14574.41\n",
      "Silhouette score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import inflection\n",
    "import re\n",
    "import pymysql\n",
    "import pickle\n",
    "import boto3\n",
    "import boto3.session\n",
    "import s3fs\n",
    "from datetime         import datetime\n",
    "from sqlalchemy       import create_engine\n",
    "from sklearn.cluster  import KMeans\n",
    "from sklearn.metrics  import silhouette_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import umap.umap_ as umap\n",
    "\n",
    "\n",
    "# Loading data ===========================================================================\n",
    "\n",
    "db_credentials = pd.read_csv('s3://gustavoawsbucketds/db_credentials.txt', header=None)\n",
    "\n",
    "\n",
    "# DB creentials\n",
    "\n",
    "user = db_credentials[0][0]\n",
    "psw = db_credentials[1][0]\n",
    "host = db_credentials[2][0]\n",
    "port = db_credentials[3][0]\n",
    "schema = db_credentials[4][0]\n",
    "schema_2 = db_credentials[5][0]\n",
    "\n",
    "\n",
    "\n",
    "# Selecting data from database - SQL query ('purchases' table - ecommerce schema)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM purchases\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}'.format(user, psw, host, port, schema))\n",
    "\n",
    "# executing sql query\n",
    "df = pd.read_sql_query(query, con=connection)\n",
    "\n",
    "# closing database connection\n",
    "connection.dispose()\n",
    "\n",
    "\n",
    "# 1 - Data description ========================================================================\n",
    "\n",
    "\n",
    "# Adjusting column names\n",
    "\n",
    "df.columns = list(map(lambda x: inflection.underscore(x), df.columns)) #changing to underscore + lower(snakecase)\n",
    "\n",
    "# Replaca NA's\n",
    "\n",
    "df = df.dropna(subset=['description', 'customer_id'])\n",
    "\n",
    "\n",
    "# Changing data types \n",
    "\n",
    "# Changing column 'invoice_date' to datetime\n",
    "\n",
    "df['invoice_date'] = pd.to_datetime(df['invoice_date'], format='%d-%b-%y')\n",
    "\n",
    "\n",
    "# Changing column 'customer_id' to int\n",
    "\n",
    "df['customer_id'] = df['customer_id'].astype(int)\n",
    "\n",
    "\n",
    "# 2 - Data filtering ========================================================================\n",
    "\n",
    "\n",
    "# Removing inconsistencies\n",
    "\n",
    "\n",
    "# 'unit_price' column:\n",
    "\n",
    "# we are going to ignore 'unit_price'==0. We will consider 'unite_price'>0.04\n",
    "\n",
    "df = df.loc[df['unit_price']>0.04, :]\n",
    "\n",
    "\n",
    "\n",
    "# 'stock_code' column:\n",
    "\n",
    "# removing the rows where the values are one of these: ['POST' 'D' 'M' 'PADS' 'DOT' 'CRUK']\n",
    "df = df.loc[~df['stock_code'].isin(['POST' 'D' 'M' 'PADS' 'DOT' 'CRUK'])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'description' column:\n",
    "\n",
    "# removing 'description' column assuming it does not have relevance information\n",
    "df = df.drop(columns='description')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'country' column (map)\n",
    "\n",
    "# removing rows where 'country' == 'European Community', 'Unspecified'\n",
    "df = df.loc[~df['country'].isin(['European Community', 'Unspecified']), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'quantity' column:\n",
    "\n",
    "# getting a dataframe with only returns operations\n",
    "df_2_returns = df.loc[df['quantity'] < 0, :]\n",
    "\n",
    "# getting a dataframe with only purchases operations\n",
    "df_2_purchases = df.loc[df['quantity'] >= 0, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Removing inconsistencies in observations:\n",
    "\n",
    "\n",
    "# based on previous univariate analysis, we investigated for some potential outliers (customers with unusual purchase behaviour)\n",
    "\n",
    "## we are going to remove these observations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'customer_id' == 16446 (this customer had two records that do not represent actual purchases, and 2 more records with only 1 item purchased each)\n",
    "## should be removed because this customer is generating distortion in the avg_ticket calculation\n",
    "\n",
    "df_2_purchases = df_2_purchases[~df_2_purchases['customer_id'].isin([16446])]\n",
    "\n",
    "\n",
    "\n",
    "# ***********************************************\n",
    "\n",
    "# Saving cleaned purchases table into a sql database to be further consumed by an external visualization tool via sql query\n",
    "\n",
    "\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(user, psw, host, port, schema_2))\n",
    "\n",
    "# inserting data to database\n",
    "df_2_purchases.to_sql( 'purchases', con=connection, if_exists='append', index=False)\n",
    "\n",
    "# ***********************************************\n",
    "\n",
    "# closing database connection\n",
    "connection.dispose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3 - Feature engineering ========================================================================\n",
    "\n",
    "\n",
    "# Feature creation\n",
    "\n",
    "\n",
    "# Creating reference dataframe\n",
    "\n",
    "df_ref = df.drop(['invoice_no', 'stock_code', 'quantity', 'invoice_date',\n",
    "                   'unit_price', 'country'], axis=1).drop_duplicates(ignore_index=True)\n",
    "\n",
    "\n",
    "# Creating 'gross_revenue' column to df_2_purchases (gross_revenue = unit_price * quantity)\n",
    "\n",
    "df_2_purchases['gross_revenue'] = df_2_purchases['unit_price'] * df_2_purchases['quantity']\n",
    "\n",
    "\n",
    "\n",
    "# Monetary (grouping 'gross_revenue' by customer)\n",
    "\n",
    "df_monetary = df_2_purchases[['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "\n",
    "\n",
    "# Joining df_ref and df_monetary\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_monetary, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recency - last day purchase (grouping 'invoice_date' by customer and getting de max date)\n",
    "\n",
    "df_recency = df_2_purchases[['customer_id', 'invoice_date']].groupby('customer_id').max().reset_index() # creating df_recency\n",
    "\n",
    "df_recency['recency'] = df_2_purchases['invoice_date'].max() - df_recency['invoice_date'] # adding 'recency' column (last purchase day of each customer - max day of dataset)\n",
    "\n",
    "df_recency['recency'] = df_recency['recency'].apply( lambda x: x.days) # extrating the number of days (from X days)\n",
    "\n",
    "\n",
    "# Joining df_ref and df_recency\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_recency[['customer_id','recency']], how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Quantity of purchases by costumer - purchase frequency of each customer\n",
    "\n",
    "df_purch_cost = df_2_purchases[['customer_id','invoice_no']].drop_duplicates().groupby('customer_id').count().reset_index()\n",
    "df_purch_cost.columns = ['customer_id', 'purchase_by_costumer'] # renaming column 'invoice' to 'purchase_by_costumer'\n",
    "\n",
    "\n",
    "# Joining df_ref and df_purch_cost\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_purch_cost, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Number of items purchased\n",
    "\n",
    "df_total_purchased = df_2_purchases[['customer_id','quantity']].groupby('customer_id').sum().reset_index()\n",
    "df_total_purchased.columns = ['customer_id', 'number_items_purchased'] # renaming column 'invoice' to 'purchase_by_costumer'\n",
    "\n",
    "\n",
    "# Joining df_ref and df_total_purchased\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_total_purchased, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Number of products purchased\n",
    "\n",
    "df_total_products = df_2_purchases[['customer_id','stock_code']].groupby('customer_id').count().reset_index()\n",
    "df_total_products.columns = ['customer_id', 'number_products_purchased'] # renaming column 'invoice' to 'purchase_by_costumer'\n",
    "\n",
    "\n",
    "# Joining df_ref and df_total_purchased\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_total_products, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Average ticket - mean purchase amount\n",
    "\n",
    "df_avg_ticket = df_2_purchases[['customer_id','gross_revenue']].groupby('customer_id').mean().reset_index()\n",
    "df_avg_ticket.columns = ['customer_id', 'avg_ticket']\n",
    "\n",
    "\n",
    "# Joining df_ref and df_avg_ticket\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_avg_ticket, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Average period between purchases\n",
    "\n",
    "\n",
    "df_aux = df_2_purchases[['customer_id', 'invoice_date']].drop_duplicates().sort_values(['customer_id','invoice_date'],\n",
    "                                                                             ascending=['False', 'False'])\n",
    "\n",
    "df_aux['previous_costumer_id'] = df_aux['customer_id'].shift() #getting next row's custumer_id\n",
    "\n",
    "df_aux['previous_invoice_date'] = df_aux['invoice_date'].shift() #getting next row's invoice_date\n",
    "\n",
    "\n",
    "df_aux['recency_days'] = df_aux.apply(lambda x: (x['invoice_date'] - x['previous_invoice_date']).days +1 \n",
    "                                                    if x['customer_id'] == x['previous_costumer_id'] else np.nan, axis=1)\n",
    "\n",
    "df_aux = df_aux.drop(columns=['invoice_date', 'previous_costumer_id', 'previous_invoice_date']) # droping auxiliary columns \n",
    "\n",
    "df_aux = df_aux.dropna() # droping Na's\n",
    "\n",
    "df_avg_recency_days = df_aux.groupby('customer_id').mean().reset_index()\n",
    "\n",
    "df_avg_recency_days.columns = ['customer_id', 'mean_recency_days']\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_avg_recency_days\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_avg_recency_days, how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Frequency purchase (mean of unique purchases/time interval between the first and the last purchase)\n",
    "\n",
    "\n",
    "df_aux = (df_2_purchases[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                                       .groupby('customer_id')\n",
    "                                                                       .agg(max_ = ('invoice_date', 'max'),\n",
    "                                                                            min_ = ('invoice_date', 'min'),\n",
    "                                                                            days_ = ('invoice_date', lambda x: (((x.max()-x.min()).days)+1)),\n",
    "                                                                            buy_ = ('invoice_no', 'count'))).reset_index()\n",
    "\n",
    "df_aux['frequency'] = df_aux[['days_', 'buy_']].apply(lambda x: x['buy_']/x['days_'] if x['days_'] != 0 else 0 , axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_aux\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_aux[['frequency', 'customer_id']], how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Returns - number of returns\n",
    "\n",
    "df_ret = (df_2_returns[['customer_id', 'quantity']].groupby('customer_id')\n",
    "                                                   .sum()\n",
    "                                                   .reset_index()\n",
    "                                                   .drop_duplicates()\n",
    "                                                   .rename(columns={'quantity':'number_of_returns'}))\n",
    " \n",
    "df_ret['number_of_returns'] = df_ret['number_of_returns']*-1 # getting positive values\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_ret\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_ret, how='left', on='customer_id')\n",
    "df_ref['number_of_returns'].fillna(0, inplace=True) # filling 'number_of_returns' with zero (when customer have never returned a product purchased)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Basket size - mean quantity (sum) of products in each purchase by costumer\n",
    "\n",
    "\n",
    "\n",
    "df_aux = (df_2_purchases[['customer_id', 'invoice_no', 'quantity']].groupby('customer_id')\n",
    "                                                                   .agg(n_purchases=('invoice_no', 'nunique'),\n",
    "                                                                        n_products=('quantity', 'sum'))\n",
    "                                                                   .reset_index())\n",
    "\n",
    "df_aux['avg_basket_size'] = df_aux['n_products']/df_aux['n_purchases'] # calculating avg basket size of each customer\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_aux\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_aux[['customer_id','avg_basket_size']], how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Basket size unique - mean quantity (sum) of unique products in each purchase by costumer\n",
    "\n",
    "\n",
    "\n",
    "df_aux = (df_2_purchases[['customer_id', 'invoice_no', 'stock_code']].groupby('customer_id')\n",
    "                                                                     .agg(n_purchases=('invoice_no', 'nunique'),\n",
    "                                                                          n_products=('stock_code', 'count'))\n",
    "                                                                     .reset_index())\n",
    "\n",
    "df_aux['avg_unique_basket_size'] = df_aux['n_products']/df_aux['n_purchases'] # calculating avg basket size of each customer\n",
    "\n",
    "\n",
    "\n",
    "# Joining df_ref and df_aux\n",
    "\n",
    "df_ref = pd.merge(left=df_ref, right=df_aux[['customer_id','avg_unique_basket_size']], how='left', on='customer_id')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5 - Data preparation ========================================================================\n",
    "\n",
    "\n",
    "#droping NA's generated from the previous step:\n",
    "df_ref = df_ref.dropna()\n",
    "\n",
    "\n",
    "# Tree-based embedding:\n",
    "\n",
    "\n",
    "# defining 'gross_revenue' as target variable\n",
    "\n",
    "y = df_ref['gross_revenue']\n",
    "\n",
    "X = df_ref.drop(columns='gross_revenue')\n",
    "X = X.set_index('customer_id')\n",
    "\n",
    "\n",
    "# Loading tree model from AWS S3\n",
    "\n",
    "# getting bucket name\n",
    "for bucket_name in boto3.resource('s3').buckets.all():\n",
    "    bucket_name = bucket_name.name\n",
    "\n",
    "\n",
    "# getting credentials\n",
    "cred = boto3.Session().get_credentials()\n",
    "ACCESS_KEY = cred.access_key\n",
    "SECRET_KEY = cred.secret_key\n",
    "\n",
    "s3client = boto3.client('s3', \n",
    "                        aws_access_key_id = ACCESS_KEY, \n",
    "                        aws_secret_access_key = SECRET_KEY\n",
    "                       )\n",
    "#responde\n",
    "response = s3client.get_object(Bucket=bucket_name, Key='rf_model.pkl')\n",
    "\n",
    "body = response['Body'].read()\n",
    "\n",
    "#tree\n",
    "rf = pickle.loads(body)\n",
    "\n",
    "\n",
    "# getting leaf information\n",
    "leaf = rf.apply(X)\n",
    "\n",
    "# df leaf\n",
    "df_leaf = pd.DataFrame(leaf)\n",
    "\n",
    "\n",
    "\n",
    "# Applying UMAP to tree-embedded data\n",
    "\n",
    "\n",
    "# loading fitted reducer from AWS S3\n",
    "\n",
    "# getting bucket name\n",
    "for bucket_name in boto3.resource('s3').buckets.all():\n",
    "    bucket_name = bucket_name.name\n",
    "\n",
    "\n",
    "# getting credentials\n",
    "cred = boto3.Session().get_credentials()\n",
    "ACCESS_KEY = cred.access_key\n",
    "SECRET_KEY = cred.secret_key\n",
    "\n",
    "s3client = boto3.client('s3', \n",
    "                        aws_access_key_id = ACCESS_KEY, \n",
    "                        aws_secret_access_key = SECRET_KEY\n",
    "                       )\n",
    "#response\n",
    "response = s3client.get_object(Bucket=bucket_name, Key='reducer_umap.pkl')\n",
    "\n",
    "body = response['Body'].read()\n",
    "\n",
    "#embedding\n",
    "reducer_umap = pickle.loads(body)\n",
    "\n",
    "embedding = reducer_umap.transform(df_leaf)\n",
    "\n",
    "# getting axis for plot and clustering\n",
    "df_tree_umap = pd.DataFrame()\n",
    "df_tree_umap['embeddings_x'] = embedding[:,0]\n",
    "df_tree_umap['embeddings_y'] = embedding[:,1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 8 - Model training ========================================================================\n",
    "\n",
    "\n",
    "# K-Means\n",
    "\n",
    "# K-Means with tree-based embeddings\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "k = 11\n",
    "\n",
    "\n",
    "# instantiating the model\n",
    "\n",
    "model_embedded = KMeans(init='random', n_clusters=k, n_init=10, max_iter=300, random_state=42)\n",
    "\n",
    "\n",
    "# fitting the model\n",
    "\n",
    "model_embedded.fit(df_tree_umap)\n",
    "\n",
    "\n",
    "# predicting labels/clusters\n",
    "\n",
    "labels_embedded = model_embedded.labels_\n",
    "\n",
    "\n",
    "# Cluster validation\n",
    "\n",
    "\n",
    "# Embedded model - metrics\n",
    "print('Kmeans metrics:\\n')\n",
    "\n",
    "# WSS\n",
    "print('WSS: {:.2f}'.format(model_embedded.inertia_))\n",
    "\n",
    "# SS\n",
    "print('Silhouette score: {:.2f}'.format(round(silhouette_score(df_tree_umap, labels_embedded, metric='euclidean', random_state=42),2)))\n",
    "\n",
    "\n",
    "\n",
    "# 9 - Cluster analysis ========================================================================\n",
    "\n",
    "\n",
    "# Adding embedded 'cluster/label' column to df_4_2 (df_4 without data transforming. For cluster profile report)\n",
    "\n",
    "\n",
    "df_ref['label'] = labels_embedded+1\n",
    "\n",
    "\n",
    "# Renaming the best cluster to \"Golden\"\n",
    "\n",
    "# getting cluster number of the Golden group\n",
    "cluster_number = df_ref[['gross_revenue', 'label']].groupby('label').mean().reset_index().sort_values(by='gross_revenue', ascending=False).iloc[0,0]\n",
    "\n",
    "# replacing the cluster number to 'Golden'\n",
    "df_ref.loc[df_ref['label']==cluster_number, 'label'] = 'Golden'\n",
    "\n",
    "# droping mean-related columns\n",
    "df_ref = df_ref.drop(columns=['avg_ticket', 'mean_recency_days', 'avg_basket_size', 'avg_unique_basket_size'])\n",
    "\n",
    "\n",
    "# changing data types\n",
    "df_ref['recency'] = df_ref['recency'].astype('int')\n",
    "\n",
    "df_ref['purchase_by_costumer'] = df_ref['purchase_by_costumer'].astype('int')\n",
    "\n",
    "df_ref['number_items_purchased'] = df_ref['number_items_purchased'].astype('int')\n",
    "\n",
    "df_ref['number_products_purchased'] = df_ref['number_products_purchased'].astype('int')\n",
    "\n",
    "df_ref['number_of_returns'] = df_ref['number_of_returns'].astype('int')\n",
    "\n",
    "\n",
    "# adding 'last_training_timestamp' column\n",
    "df_ref['last_training_timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_ref['last_training_timestamp'] = pd.to_datetime(df_ref['last_training_timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "\n",
    "# ***********************************************\n",
    "\n",
    "# Inserting data to sql database using SQLAlchemy (SQLAlchemy is able to insert data into several databases)\n",
    "\n",
    "# creating the conection to existing db\n",
    "connection = create_engine('mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(user, psw, host, port, schema_2))\n",
    "\n",
    "# inserting data to database\n",
    "df_ref.to_sql( 'customers', con=connection, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "# ***********************************************\n",
    "\n",
    "# closing database connection\n",
    "connection.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8cee8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb54bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f758a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# References:\n",
    "\n",
    "# MySQL AWS RDS config/settings:https://www.youtube.com/watch?v=RerDL93sBdY\n",
    "\n",
    "# Loading .pkl files from AWS S3 bucket: ttps://towardsdatascience.com/how-to-load-data-from-a-pickle-file-in-s3-using-python-ffe2866b7eba\n",
    "\n",
    "# Installing AWS CLI in Ubuntu: https://linuxhint.com/install_aws_cli_ubuntu/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
